#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Leaf Detection Handler
Handles leaf detection using PlantCV library
"""

import cv2
import numpy as np
from plantcv import plantcv as pcv
from cv_bridge import CvBridge
from datetime import datetime
import json
from std_msgs.msg import String
from sensor_msgs.msg import Image


class DetectionHandler:
    """Handles leaf detection logic using PlantCV"""
    
    def __init__(self, node, tf_handler=None):
        self.node = node
        self.tf_handler = tf_handler
        self.bridge = CvBridge()
        
        # PlantCV settings
        pcv.params.debug = None  # Disable debug output
        
        # Current frame data
        self.current_frame = None
        self.current_depth = None
        
        # Latest detection results (for service to use)
        self.latest_leaf_data = None
        self.latest_coordinates_base = None
        self.latest_leaf_attributes = {
            'has_yellow_tape': [],
            'yellow_ratio': [],
            'health_status': []
        }
        import threading
        self.latest_data_lock = threading.Lock()
        
        # Track published blue box IDs for cleanup
        self.published_blue_box_ids = set()  # Track which box IDs have been published to MoveIt
        
        # Detection mode: continuous or on-demand
        self.continuous_detection = node.declare_parameter('continuous_detection', True).value
        self.min_area_default = 2000.0  # Default min area
        self.detect_yellow_tape = node.declare_parameter('detect_yellow_tape', True).value
        self.yellow_ratio_threshold = node.declare_parameter('yellow_ratio_threshold', 0.05).value  # é™ä½é˜ˆå€¼åˆ°0.05ï¼ˆ5%ï¼‰ä»¥æ›´å®¹æ˜“æ£€æµ‹é»„è‰²èƒ¶å¸ƒ
        # HSVé¢œè‰²èŒƒå›´å‚æ•°ï¼ˆå¯é…ç½®ï¼Œé»˜è®¤æ›´ä¸¥æ ¼ä»¥æ£€æµ‹çœŸæ­£çš„é»„è‰²èƒ¶å¸ƒï¼‰
        # é»„è‰²èƒ¶å¸ƒé€šå¸¸æ˜¯äº®é»„è‰²ï¼Œé¥±å’Œåº¦å’Œäº®åº¦éƒ½è¾ƒé«˜
        self.yellow_hsv_lower = node.declare_parameter('yellow_hsv_lower', [20, 100, 100]).value
        self.yellow_hsv_upper = node.declare_parameter('yellow_hsv_upper', [30, 255, 255]).value
        
        # è“è‰²ç›’å­æ£€æµ‹å‚æ•°
        self.detect_blue_box = node.declare_parameter('detect_blue_box', True).value
        self.blue_min_area = node.declare_parameter('blue_min_area', 3000.0).value
        # è“è‰²åœ¨HSVä¸­ï¼šHå€¼åœ¨100-130ä¹‹é—´ï¼ˆè“è‰²èŒƒå›´ï¼‰ï¼ŒSå’ŒVå€¼è¾ƒé«˜
        # ä½¿ç”¨è°ƒæ•´åçš„å‚æ•°ï¼šS Lower=147 ä»¥å‡å°‘è¯¯æ£€
        self.blue_hsv_lower = node.declare_parameter('blue_hsv_lower', [100, 147, 50]).value
        self.blue_hsv_upper = node.declare_parameter('blue_hsv_upper', [130, 255, 255]).value
        
        # Publisher for detection results (for visualization node to subscribe)
        self.detection_results_pub = node.create_publisher(
            String,
            '/leaf_detection/detection_results',
            10
        )
        
        # Publisher for annotated image (continuously published)
        self.annotated_image_pub = node.create_publisher(
            Image,
            '/leaf_detection/annotated_image',
            10
        )
        
        self.healthy_leaves_pub = node.create_publisher(
            String,
            '/leaf_detection/healthy_leaves',
            10
        )
        self.unhealthy_leaves_pub = node.create_publisher(
            String,
            '/leaf_detection/unhealthy_leaves',
            10
        )
        
        # Publisher for blue box detection results
        self.blue_box_results_pub = node.create_publisher(
            String,
            '/leaf_detection/blue_box_results',
            10
        )
        
        # Publisher for MoveIt CollisionObjects (for dynamic_obstacles_monitor)
        from moveit_msgs.msg import CollisionObject
        self.moveit_collision_pub = node.create_publisher(
            CollisionObject,
            '/obsFromImg',
            10
        )
        
        self.get_logger().info('âœ“ DetectionHandler initialized')
        if self.continuous_detection:
            self.get_logger().info('ğŸ“¡ Continuous detection mode: images will be published continuously')
        if self.detect_yellow_tape:
            self.get_logger().info(
                f'ğŸ¯ Yellow tape detection enabled (threshold={self.yellow_ratio_threshold:.3f}, '
                f'HSV range: {self.yellow_hsv_lower} - {self.yellow_hsv_upper})'
            )
        if self.detect_blue_box:
            self.get_logger().info(
                f'ğŸ“¦ Blue box detection enabled (min_area={self.blue_min_area}, '
                f'HSV range: {self.blue_hsv_lower} - {self.blue_hsv_upper})'
            )
    
    def get_logger(self):
        """Get node logger"""
        return self.node.get_logger()
    
    def update_frames(self, color_msg, depth_msg):
        """Update current frame and depth from synchronized messages, and perform continuous detection"""
        try:
            self.current_frame = self.bridge.imgmsg_to_cv2(color_msg, 'bgr8')
            self.current_depth = self.bridge.imgmsg_to_cv2(depth_msg, 'passthrough')
            
            # Continuous detection mode: detect and publish on every frame
            if self.continuous_detection:
                self._perform_continuous_detection(color_msg.header)
        except Exception as e:
            self.get_logger().error(f'âœ— Image conversion failed: {str(e)}')
            import traceback
            self.get_logger().error(traceback.format_exc())
    
    def _perform_continuous_detection(self, header):
        """Perform detection on current frame and publish results continuously"""
        # Frame counter for debugging
        if not hasattr(self, '_frame_count'):
            self._frame_count = 0
        self._frame_count += 1
        
        if self.current_frame is None:
            self.get_logger().warn(f'Frame {self._frame_count}: current_frame is None')
            return
        
        if self.current_depth is None:
            self.get_logger().warn(f'Frame {self._frame_count}: current_depth is None, skipping detection')
            return
        
        try:
            # Perform detection with default parameters
            detection_result, leaf_data, bounding_boxes = self.detect_leaves_with_plantcv(
                self.current_frame,
                min_area=self.min_area_default
            )
            
            # Log detection status periodically
            if self._frame_count % 30 == 0:
                if leaf_data and leaf_data.get('num_leaves', 0) > 0:
                    self.get_logger().info(f'Frame {self._frame_count}: Detected {leaf_data["num_leaves"]} leaves, publishing image...')
                else:
                    self.get_logger().debug(f'Frame {self._frame_count}: No leaves detected, publishing original image...')
            
            # Update latest results (thread-safe)
            with self.latest_data_lock:
                if leaf_data and leaf_data.get('num_leaves', 0) > 0:
                    self.latest_leaf_data = leaf_data
                    # Also compute base coordinates for latest data
                    self.latest_coordinates_base = self._convert_to_base_coordinates(leaf_data.get('coordinates', []))
                    has_yellow, yellow_ratio, health_status = self._extract_leaf_attributes(
                        leaf_data.get('coordinates', [])
                    )
                    self.latest_leaf_attributes = {
                        'has_yellow_tape': has_yellow,
                        'yellow_ratio': yellow_ratio,
                        'health_status': health_status
                    }
                    
                    # Log base frame coordinates periodically
                    if self._frame_count % 30 == 0 and self.latest_coordinates_base:
                        self.get_logger().info('ğŸ“ Latest base coordinates:')
                        for i, point in enumerate(self.latest_coordinates_base):
                            self.get_logger().info(f'  Leaf {i+1}: X={point.x:.3f}m, Y={point.y:.3f}m, Z={point.z:.3f}m')
                else:
                    self.latest_leaf_data = None
                    self.latest_coordinates_base = []
                    self.latest_leaf_attributes = {
                        'has_yellow_tape': [],
                        'yellow_ratio': [],
                        'health_status': []
                    }
            
            # Publish health status summary
            self._publish_health_status(leaf_data)
            
            # Publish detection results to topic (for visualization node)
            if leaf_data:
                # Convert to base coordinates if tf_handler is available
                base_coords_list = []
                if self.tf_handler:
                    base_coords_msg = self._convert_to_base_coordinates(leaf_data.get('coordinates', []))
                    # Convert Point messages to dict for JSON serialization
                    for point_msg in base_coords_msg:
                        base_coords_list.append({
                            'x': point_msg.x,
                            'y': point_msg.y,
                            'z': point_msg.z
                        })
                
                # Clean blue boxes for JSON serialization (remove numpy arrays)
                blue_boxes_clean = self._clean_blue_boxes_for_json(leaf_data.get('blue_boxes', []))
                
                results_json = {
                    'num_leaves': leaf_data['num_leaves'],
                    'timestamp': leaf_data.get('timestamp', ''),
                    'coordinates': leaf_data.get('coordinates', []),  # Camera frame coordinates
                    'base_coordinates': base_coords_list if base_coords_list else [],  # Base frame coordinates
                    'blue_boxes': blue_boxes_clean  # Blue box coordinates (cleaned for JSON)
                }
                results_msg = String()
                results_msg.data = json.dumps(results_json)
                self.detection_results_pub.publish(results_msg)
                
                # Publish blue box results separately
                blue_boxes = leaf_data.get('blue_boxes', [])
                if len(blue_boxes) > 0:
                    blue_box_json = {
                        'num_blue_boxes': len(blue_boxes),
                        'timestamp': leaf_data.get('timestamp', ''),
                        'blue_boxes': blue_boxes_clean
                    }
                    blue_box_msg = String()
                    blue_box_msg.data = json.dumps(blue_box_json)
                    self.blue_box_results_pub.publish(blue_box_msg)
                    
                    # Publish blue boxes as MoveIt CollisionObjects to /obsFromImg
                    self._publish_blue_boxes_to_moveit(blue_boxes)
                else:
                    # No blue boxes detected: remove all previously published boxes
                    self._publish_blue_boxes_to_moveit([])
            else:
                # Publish empty results if no leaves detected
                results_json = {
                    'num_leaves': 0,
                    'timestamp': datetime.now().isoformat(),
                    'coordinates': [],
                    'blue_boxes': []
                }
                results_msg = String()
                results_msg.data = json.dumps(results_json)
                self.detection_results_pub.publish(results_msg)
            
            # Publish annotated image (with or without detections)
            annotated_image = self.draw_annotations(
                self.current_frame, 
                leaf_data.get('coordinates', []) if leaf_data else [],
                leaf_data.get('blue_boxes', []) if leaf_data else []
            )
            if annotated_image is not None:
                try:
                    annotated_msg = self.bridge.cv2_to_imgmsg(annotated_image, "bgr8")
                    annotated_msg.header = header
                    self.annotated_image_pub.publish(annotated_msg)
                except Exception as e:
                    self.get_logger().error(f'âœ— Error publishing annotated image: {str(e)}')
                    import traceback
                    self.get_logger().error(traceback.format_exc())
                    
        except Exception as e:
            self.get_logger().error(f'âœ— Continuous detection error: {str(e)}')
            import traceback
            self.get_logger().error(traceback.format_exc())
            # Still publish original image even if detection fails
            try:
                annotated_msg = self.bridge.cv2_to_imgmsg(self.current_frame, "bgr8")
                annotated_msg.header = header
                self.annotated_image_pub.publish(annotated_msg)
            except:
                pass
    
    def _publish_health_status(self, leaf_data):
        """Publish healthy/unhealthy leaf summaries as separate topics"""
        healthy_leaves = []
        unhealthy_leaves = []
        
        if leaf_data and leaf_data.get('coordinates'):
            for leaf in leaf_data['coordinates']:
                is_unhealthy = bool(leaf.get('has_yellow_tape', False))
                payload = {
                    'id': leaf.get('id'),
                    'center': leaf.get('center', {}),
                    'bounding_box': leaf.get('bounding_box', {}),
                    'yellow_ratio': leaf.get('yellow_ratio', 0.0),
                    'health_status': 'unhealthy' if is_unhealthy else 'healthy'
                }
                if is_unhealthy:
                    unhealthy_leaves.append(payload)
                else:
                    healthy_leaves.append(payload)
        else:
            # No leaves detected, publish empty payloads
            healthy_leaves = []
            unhealthy_leaves = []
        
        healthy_msg = String()
        healthy_msg.data = json.dumps({
            'timestamp': datetime.now().isoformat(),
            'num_leaves': len(healthy_leaves),
            'leaves': healthy_leaves
        })
        unhealthy_msg = String()
        unhealthy_msg.data = json.dumps({
            'timestamp': datetime.now().isoformat(),
            'num_leaves': len(unhealthy_leaves),
            'leaves': unhealthy_leaves
        })
        
        self.healthy_leaves_pub.publish(healthy_msg)
        self.unhealthy_leaves_pub.publish(unhealthy_msg)
    
    def _convert_to_base_coordinates(self, leaf_coordinates):
        """Convert leaf coordinates to base frame"""
        coordinates = []
        from geometry_msgs.msg import Point
        
        if self.tf_handler:
            for i, leaf in enumerate(leaf_coordinates):
                point_3d = leaf.get('point_3d')
                if point_3d is not None:
                    # Log original camera optical frame coordinates
                    self.get_logger().debug(
                        f'Leaf {i+1} - Camera optical frame: '
                        f'({point_3d[0]:.3f}, {point_3d[1]:.3f}, {point_3d[2]:.3f})'
                    )
                    
                    base_coords = self.tf_handler.camera_to_base(point_3d)
                    if base_coords:
                        self.get_logger().debug(
                            f'Leaf {i+1} - Base_link frame (after TF + offsets): '
                            f'({base_coords[0]:.3f}, {base_coords[1]:.3f}, {base_coords[2]:.3f})'
                        )
                        
                        point_msg = Point()
                        point_msg.x = float(base_coords[0])
                        point_msg.y = float(base_coords[1])
                        point_msg.z = float(base_coords[2])
                        coordinates.append(point_msg)
                    else:
                        self.get_logger().warn(f'Leaf {i+1} - Failed to convert to base coordinates')
        else:
            for leaf in leaf_coordinates:
                point_3d = leaf.get('point_3d')
                if point_3d is not None:
                    point_msg = Point()
                    point_msg.x = float(point_3d[0])
                    point_msg.y = float(point_3d[1])
                    point_msg.z = float(point_3d[2])
                    coordinates.append(point_msg)
        
        return coordinates
    
    def _extract_leaf_attributes(self, leaf_records):
        """Extract yellow tape indicators and health labels from detection results"""
        has_yellow = []
        yellow_ratio = []
        health_status = []
        for leaf in leaf_records or []:
            has_yellow.append(bool(leaf.get('has_yellow_tape', False)))
            yellow_ratio.append(float(leaf.get('yellow_ratio', 0.0)))
            health_status.append(str(leaf.get('health_status', 'unknown')))
        return has_yellow, yellow_ratio, health_status
    
    def _clean_blue_boxes_for_json(self, blue_boxes):
        """Clean blue box data for JSON serialization (remove numpy arrays)"""
        cleaned = []
        for box in blue_boxes:
            cleaned_box = {
                'id': box.get('id'),
                'type': box.get('type'),
                'num_faces': box.get('num_faces', 1),
                'center': box.get('center', {}),
                'bounding_box': box.get('bounding_box', {}),
                'area': box.get('area', 0.0),
                'depth_mm': box.get('depth_mm', 0.0),
                'point_3d': list(box.get('point_3d')) if box.get('point_3d') is not None else None,
                'size_3d': box.get('size_3d')
            }
            # Remove 'faces' field as it contains numpy arrays (contours)
            cleaned.append(cleaned_box)
        return cleaned
    
    def _publish_blue_boxes_to_moveit(self, blue_boxes):
        """Publish blue boxes as MoveIt CollisionObjects to /obsFromImg"""
        from moveit_msgs.msg import CollisionObject
        from std_msgs.msg import Header
        
        # Get current box IDs
        current_box_ids = set()
        
        for box in blue_boxes:
            point_3d = box.get('point_3d')
            size_3d = box.get('size_3d')
            
            if point_3d is None or size_3d is None:
                continue
            
            box_id = f"blue_box_{box['id']:03d}"
            current_box_ids.add(box_id)
            
            # Convert camera frame coordinates to base frame if tf_handler is available
            base_point_3d = point_3d
            if self.tf_handler:
                base_coords = self.tf_handler.camera_to_base(point_3d)
                if base_coords:
                    base_point_3d = base_coords
                else:
                    self.get_logger().warn(f'Failed to convert blue box {box.get("id")} to base frame, removing old marker')
                    # If conversion fails, remove the old marker if it exists
                    if box_id in self.published_blue_box_ids:
                        self._remove_blue_box_from_moveit(box_id)
                        self.published_blue_box_ids.discard(box_id)
                    continue
            
            # Create CollisionObject message
            collision_obj = CollisionObject()
            collision_obj.header = Header()
            collision_obj.header.frame_id = "base_link"  # Use base_link frame for MoveIt
            collision_obj.header.stamp = self.node.get_clock().now().to_msg()
            
            collision_obj.id = box_id
            collision_obj.operation = CollisionObject.ADD  # 0 = ADD
            
            # Set primitive (box)
            from shape_msgs.msg import SolidPrimitive
            primitive = SolidPrimitive()
            primitive.type = SolidPrimitive.BOX  # 1 = BOX
            primitive.dimensions = [
                float(size_3d['width']),
                float(size_3d['height']),
                float(size_3d['depth'])
            ]
            collision_obj.primitives = [primitive]
            
            # Set pose
            from geometry_msgs.msg import Pose
            pose = Pose()
            pose.position.x = float(base_point_3d[0])
            pose.position.y = float(base_point_3d[1])
            pose.position.z = float(base_point_3d[2])
            pose.orientation.w = 1.0  # No rotation
            collision_obj.primitive_poses = [pose]
            
            # Publish
            self.moveit_collision_pub.publish(collision_obj)
            self.published_blue_box_ids.add(box_id)
            self.get_logger().debug(
                f'Published blue box {collision_obj.id} to /obsFromImg: '
                f'pos=({base_point_3d[0]:.3f}, {base_point_3d[1]:.3f}, {base_point_3d[2]:.3f}), '
                f'size=({size_3d["width"]:.3f}, {size_3d["height"]:.3f}, {size_3d["depth"]:.3f})'
            )
        
        # Remove boxes that are no longer detected
        boxes_to_remove = self.published_blue_box_ids - current_box_ids
        for box_id in boxes_to_remove:
            self._remove_blue_box_from_moveit(box_id)
            self.published_blue_box_ids.discard(box_id)
    
    def _remove_blue_box_from_moveit(self, box_id):
        """Remove a blue box from MoveIt planning scene"""
        from moveit_msgs.msg import CollisionObject
        from std_msgs.msg import Header
        
        collision_obj = CollisionObject()
        collision_obj.header = Header()
        collision_obj.header.frame_id = "base_link"
        collision_obj.header.stamp = self.node.get_clock().now().to_msg()
        collision_obj.id = box_id
        collision_obj.operation = CollisionObject.REMOVE  # 1 = REMOVE
        
        self.moveit_collision_pub.publish(collision_obj)
        self.get_logger().debug(f'Removed blue box {box_id} from MoveIt planning scene')
    
    async def handle_request(self, request):
        """Handle detection service request"""
        if request.command == "detect":
            return await self._detect_leaves(request)
        else:
            return {
                'success': False,
                'message': f"Unknown command: {request.command}",
                'coordinates': [],
                'num_leaves': 0,
                'has_yellow_tape': [],
                'yellow_ratio': [],
                'health_status': [],
                'debug_info': ''
            }
    
    async def _detect_leaves(self, request):
        """Handle detection service request - use latest results or re-detect with custom params"""
        if self.current_frame is None or self.current_depth is None:
            return {
                'success': False,
                'message': "No frame available",
                'coordinates': [],
                'num_leaves': 0,
                'has_yellow_tape': [],
                'yellow_ratio': [],
                'health_status': [],
                'debug_info': ''
            }
        
        try:
            # If min_area is 0 or matches default, use latest continuous detection results
            use_custom_params = (request.min_area > 0 and request.min_area != self.min_area_default)
            
            if not use_custom_params and self.continuous_detection:
                # Use latest detection results (faster, no re-computation)
                with self.latest_data_lock:
                    if self.latest_coordinates_base is not None:
                        num_leaves = len(self.latest_coordinates_base)
                        if num_leaves > 0:
                            attrs = self.latest_leaf_attributes
                            return {
                                'success': True,
                                'message': f"Detected {num_leaves} leaves (using latest continuous detection)",
                                'coordinates': self.latest_coordinates_base.copy(),
                                'num_leaves': num_leaves,
                                'has_yellow_tape': list(attrs.get('has_yellow_tape', [])),
                                'yellow_ratio': list(attrs.get('yellow_ratio', [])),
                                'health_status': list(attrs.get('health_status', [])),
                                'debug_info': json.dumps({
                                    'source': 'latest_continuous_detection',
                                    'has_base_coords': self.tf_handler is not None
                                })
                            }
                        else:
                            return {
                                'success': False,
                                'message': "No leaves detected in latest frame",
                                'coordinates': [],
                                'num_leaves': 0,
                                'has_yellow_tape': [],
                                'yellow_ratio': [],
                                'health_status': [],
                                'debug_info': json.dumps({'source': 'latest_continuous_detection'})
                            }
            
            # Re-detect with custom parameters or if continuous detection is disabled
            min_area = request.min_area if request.min_area > 0 else self.min_area_default
            detection_result, leaf_data, bounding_boxes = self.detect_leaves_with_plantcv(
                self.current_frame,
                min_area=min_area
            )
            
            if leaf_data is None or leaf_data.get('num_leaves', 0) == 0:
                return {
                    'success': False,
                    'message': detection_result,
                    'coordinates': [],
                    'num_leaves': 0,
                    'has_yellow_tape': [],
                    'yellow_ratio': [],
                    'health_status': [],
                    'debug_info': json.dumps({'detection_result': detection_result, 'min_area': min_area})
                }
            
            # Convert to base frame coordinates
            coordinates = self._convert_to_base_coordinates(leaf_data.get('coordinates', []))
            has_yellow, yellow_ratio, health_status = self._extract_leaf_attributes(
                leaf_data.get('coordinates', [])
            )
            
            return {
                'success': True,
                'message': f"Detected {len(coordinates)} leaves",
                'coordinates': coordinates,
                'num_leaves': len(coordinates),
                'has_yellow_tape': has_yellow,
                'yellow_ratio': yellow_ratio,
                'health_status': health_status,
                'debug_info': json.dumps({
                    'num_leaves': leaf_data['num_leaves'],
                    'timestamp': leaf_data.get('timestamp', ''),
                    'has_base_coords': self.tf_handler is not None,
                    'min_area': min_area,
                    'source': 'on_demand_detection'
                })
            }
            
        except Exception as e:
            self.get_logger().error(f"Detection error: {str(e)}")
            import traceback
            return {
                'success': False,
                'message': f"Detection failed: {str(e)}",
                'coordinates': [],
                'num_leaves': 0,
                'has_yellow_tape': [],
                'yellow_ratio': [],
                'health_status': [],
                'debug_info': json.dumps({'error': str(e), 'traceback': traceback.format_exc()})
            }
    
    def measure_box_dimensions_3d(self, bbox_2d, depth_image, mask=None, sample_step=3):
        """
        ä½¿ç”¨æ·±åº¦å›¾æµ‹é‡ç›’å­çš„å®é™…3Då°ºå¯¸ï¼ˆåŸºäºbox_dimensioneræ–¹æ³•ï¼‰
        
        è¯¥æ–¹æ³•å‚è€ƒRealSense SDKçš„box_dimensionerç¤ºä¾‹ï¼š
        1. åœ¨æ£€æµ‹åŒºåŸŸå†…å¯†é›†é‡‡æ ·3Dç‚¹
        2. ä½¿ç”¨ç»Ÿè®¡æ–¹æ³•å»é™¤å¼‚å¸¸å€¼
        3. è®¡ç®—3Dè¾¹ç•Œæ¡†å¾—åˆ°é•¿å®½é«˜
        
        Args:
            bbox_2d: 2Dè¾¹ç•Œæ¡† (x_min, y_min, x_max, y_max) åœ¨åŸå§‹å›¾åƒåæ ‡ç³»
            depth_image: æ·±åº¦å›¾åƒï¼ˆ16ä½ï¼Œå•ä½ï¼šæ¯«ç±³ï¼‰
            mask: å¯é€‰çš„æ©ç ï¼ˆå¦‚æœæä¾›ï¼Œåªé‡‡æ ·æ©ç å†…çš„ç‚¹ï¼‰
            sample_step: é‡‡æ ·æ­¥é•¿ï¼ˆåƒç´ ï¼‰ï¼Œé»˜è®¤3ï¼ˆæ›´å¯†é›†é‡‡æ ·ä»¥æé«˜ç²¾åº¦ï¼‰
        
        Returns:
            dict: {
                'width': é•¿åº¦ï¼ˆç±³ï¼ŒXæ–¹å‘ï¼‰,
                'height': é«˜åº¦ï¼ˆç±³ï¼ŒYæ–¹å‘ï¼‰,
                'depth': å®½åº¦ï¼ˆç±³ï¼ŒZæ–¹å‘ï¼‰,
                'points_3d': é‡‡æ ·åˆ°çš„3Dç‚¹åˆ—è¡¨,
                'min_point': æœ€å°è¾¹ç•Œç‚¹ (x, y, z),
                'max_point': æœ€å¤§è¾¹ç•Œç‚¹ (x, y, z),
                'num_samples': é‡‡æ ·ç‚¹æ•°
            } æˆ– Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        if depth_image is None or self.tf_handler is None or self.tf_handler.intrinsics is None:
            return None
        
        x_min, y_min, x_max, y_max = bbox_2d
        
        # ç¡®ä¿åæ ‡åœ¨å›¾åƒèŒƒå›´å†…
        x_min = max(0, int(x_min))
        y_min = max(0, int(y_min))
        x_max = min(depth_image.shape[1], int(x_max))
        y_max = min(depth_image.shape[0], int(y_max))
        
        if x_max <= x_min or y_max <= y_min:
            return None
        
        # æ–¹æ³•1ï¼šå¯†é›†é‡‡æ ·3Dç‚¹ï¼ˆç±»ä¼¼box_dimensionerçš„æ ¸å¿ƒæ–¹æ³•ï¼‰
        points_3d = []
        valid_depths = []
        
        # åœ¨è¾¹ç•Œæ¡†å†…å¯†é›†é‡‡æ ·
        for y in range(y_min, y_max, sample_step):
            for x in range(x_min, x_max, sample_step):
                # å¦‚æœæä¾›äº†æ©ç ï¼Œæ£€æŸ¥è¯¥ç‚¹æ˜¯å¦åœ¨æ©ç å†…
                if mask is not None:
                    if (y < 0 or y >= mask.shape[0] or 
                        x < 0 or x >= mask.shape[1] or
                        mask[y, x] == 0):
                        continue
                
                # è·å–æ·±åº¦å€¼
                depth_mm = depth_image[y, x]
                
                # è¿‡æ»¤æ— æ•ˆæ·±åº¦ï¼ˆæ›´ä¸¥æ ¼çš„è¿‡æ»¤ï¼‰
                if depth_mm <= 0 or depth_mm > 5000:
                    continue
                
                # è½¬æ¢ä¸º3Dåæ ‡ï¼ˆä½¿ç”¨tf_handlerçš„æ–¹æ³•ï¼‰
                point_3d = self.tf_handler.pixel_to_3d(x, y, depth_mm)
                if point_3d is not None:
                    points_3d.append(point_3d)
                    valid_depths.append(depth_mm)
        
        if len(points_3d) < 8:  # è‡³å°‘éœ€è¦8ä¸ªç‚¹æ‰èƒ½å‡†ç¡®ä¼°ç®—å°ºå¯¸
            return None
        
        # æ–¹æ³•2ï¼šä½¿ç”¨ç»Ÿè®¡æ–¹æ³•å»é™¤å¼‚å¸¸å€¼ï¼ˆç±»ä¼¼box_dimensionerçš„é²æ£’æ€§å¤„ç†ï¼‰
        points_array = np.array(points_3d)
        depths_array = np.array(valid_depths)
        
        # è®¡ç®—æ·±åº¦ä¸­ä½æ•°ï¼Œå»é™¤ç¦»ç¾¤ç‚¹ï¼ˆæ·±åº¦å·®å¼‚è¿‡å¤§å¯èƒ½æ˜¯èƒŒæ™¯æˆ–å™ªå£°ï¼‰
        median_depth = np.median(depths_array)
        depth_std = np.std(depths_array)
        depth_threshold = median_depth + 3 * depth_std  # 3å€æ ‡å‡†å·®
        
        # è¿‡æ»¤å¼‚å¸¸æ·±åº¦ç‚¹
        valid_mask = depths_array <= depth_threshold
        filtered_points = points_array[valid_mask]
        
        if len(filtered_points) < 8:
            filtered_points = points_array  # å¦‚æœè¿‡æ»¤åç‚¹æ•°å¤ªå°‘ï¼Œä½¿ç”¨åŸå§‹ç‚¹
        
        # æ–¹æ³•3ï¼šè®¡ç®—3Dè¾¹ç•Œæ¡†ï¼ˆbox_dimensionerçš„æ ¸å¿ƒï¼‰
        # æ‰¾åˆ°æ‰€æœ‰ç‚¹çš„æœ€å°/æœ€å¤§X, Y, Zå€¼
        min_point = filtered_points.min(axis=0)  # [min_x, min_y, min_z]
        max_point = filtered_points.max(axis=0)   # [max_x, max_y, max_z]
        
        # è®¡ç®—å°ºå¯¸ï¼ˆåœ¨ç›¸æœºåæ ‡ç³»ä¸­ï¼‰
        # Xæ–¹å‘ = é•¿åº¦ï¼ˆå·¦å³ï¼Œé€šå¸¸æ˜¯æœ€é•¿çš„è¾¹ï¼‰
        # Yæ–¹å‘ = é«˜åº¦ï¼ˆä¸Šä¸‹ï¼‰
        # Zæ–¹å‘ = å®½åº¦ï¼ˆå‰åï¼Œè·ç¦»ç›¸æœºçš„è¿œè¿‘ï¼Œé€šå¸¸æ˜¯æœ€çŸ­çš„è¾¹ï¼‰
        length = float(max_point[0] - min_point[0])   # Xæ–¹å‘
        height = float(max_point[1] - min_point[1])    # Yæ–¹å‘
        width = float(max_point[2] - min_point[2])      # Zæ–¹å‘
        
        # æ–¹æ³•4ï¼šå¦‚æœå®½åº¦ï¼ˆZæ–¹å‘ï¼‰å¤ªå°ï¼Œå¯èƒ½æ˜¯åªçœ‹åˆ°äº†ä¸€ä¸ªé¢
        # ä½¿ç”¨æ·±åº¦å˜åŒ–æ¥ä¼°ç®—å®½åº¦ï¼ˆç±»ä¼¼box_dimensionerå¤„ç†å•è§†è§’æƒ…å†µï¼‰
        if width < 0.01:  # å°äº1cmï¼Œå¯èƒ½åªçœ‹åˆ°ä¸€ä¸ªé¢
            z_values = filtered_points[:, 2]
            z_std = float(np.std(z_values))
            if z_std > 0.003:  # å¦‚æœæ ‡å‡†å·®å¤§äº3mmï¼Œè¯´æ˜æœ‰æ·±åº¦å˜åŒ–
                # ä½¿ç”¨ç»Ÿè®¡æ–¹æ³•ä¼°ç®—ï¼š2å€æ ‡å‡†å·® + ä¸­ä½æ•°èŒƒå›´
                z_range = np.percentile(z_values, 95) - np.percentile(z_values, 5)
                width = max(z_range, z_std * 2.5)  # ä½¿ç”¨æ›´ä¿å®ˆçš„ä¼°ç®—
            else:
                # å¦‚æœæ·±åº¦å˜åŒ–å¾ˆå°ï¼Œä½¿ç”¨åƒç´ å°ºå¯¸ä¼°ç®—
                pixel_width = x_max - x_min
                avg_depth = float(np.median(z_values))
                if avg_depth > 0 and self.tf_handler.intrinsics:
                    pixel_size = avg_depth / self.tf_handler.intrinsics.fx
                    width = pixel_width * pixel_size * 0.3  # ä¿å®ˆä¼°ç®—ä¸ºåƒç´ å®½åº¦çš„30%
                else:
                    width = 0.1  # é»˜è®¤10cm
        
        # ç¡®ä¿æœ€å°å°ºå¯¸åˆç†ï¼ˆè‡³å°‘1cmï¼‰
        length = max(length, 0.01)
        height = max(height, 0.01)
        width = max(width, 0.01)
        
        return {
            'width': length,   # Xæ–¹å‘ï¼ˆé•¿åº¦ï¼‰
            'height': height,  # Yæ–¹å‘ï¼ˆé«˜åº¦ï¼‰
            'depth': width,    # Zæ–¹å‘ï¼ˆå®½åº¦ï¼‰
            'points_3d': filtered_points.tolist(),
            'min_point': tuple(min_point),
            'max_point': tuple(max_point),
            'num_samples': len(filtered_points),
            'median_depth': float(np.median(depths_array)) if len(depths_array) > 0 else 0.0
        }
    
    def detect_leaves_with_plantcv(self, cv_image, min_area=None):
        """
        Detect leaves using PlantCV library
        Returns: (detection_result_string, leaf_data_dict, bounding_boxes_list)
        """
        try:
            h, w = cv_image.shape[:2]
            
            # Minimal cropping
            crop_img = pcv.crop(img=cv_image, x=20, y=20, h=h-40, w=w-40)
            
            # HSV color space - detect green and optional yellow tape
            hsv = cv2.cvtColor(crop_img, cv2.COLOR_BGR2HSV)
            lower_green = np.array([40, 60, 40])
            upper_green = np.array([80, 255, 255])
            thresh_green = cv2.inRange(hsv, lower_green, upper_green)
            thresh_green = (thresh_green / 255).astype(np.uint8)
            
            # æ­¥éª¤2.5: æ£€æµ‹è“è‰²ç›’å­ï¼ˆç‹¬ç«‹äºå¶å­æ£€æµ‹ï¼‰
            blue_box_coordinates = []
            if self.detect_blue_box:
                # ä½¿ç”¨HSVé¢œè‰²ç©ºé—´æ£€æµ‹è“è‰²
                lower_blue_hsv = np.array(self.blue_hsv_lower, dtype=np.uint8)
                upper_blue_hsv = np.array(self.blue_hsv_upper, dtype=np.uint8)
                thresh_blue_hsv = cv2.inRange(hsv, lower_blue_hsv, upper_blue_hsv)
                
                # å½¢æ€å­¦å¤„ç†ï¼šå»é™¤å°å™ªå£°ï¼Œè¿æ¥ç›¸è¿‘åŒºåŸŸ
                kernel_blue_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
                kernel_blue_medium = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7, 7))
                
                # å…ˆé—­è¿ç®—è¿æ¥ç›¸è¿‘åŒºåŸŸï¼Œå†å¼€è¿ç®—å»é™¤å°å™ªå£°
                thresh_blue_morph = cv2.morphologyEx(thresh_blue_hsv, cv2.MORPH_CLOSE, kernel_blue_medium, iterations=2)
                thresh_blue_morph = cv2.morphologyEx(thresh_blue_morph, cv2.MORPH_OPEN, kernel_blue_small, iterations=1)
                
                # æ£€æµ‹è“è‰²ç›’å­çš„è½®å»“ï¼ˆåŒ…æ‹¬æ‰€æœ‰å±‚çº§ï¼Œä»¥æ£€æµ‹å¤šä¸ªé¢ï¼‰
                blue_contours, blue_hierarchy = cv2.findContours(thresh_blue_morph, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
                
                # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„è“è‰²åŒºåŸŸï¼ˆå¯èƒ½æ˜¯ç›’å­çš„ä¸åŒé¢ï¼‰
                valid_blue_regions = []
                
                # è¿‡æ»¤è“è‰²ç›’å­è½®å»“ï¼ˆæ£€æµ‹æ‰€æœ‰å¯è§é¢ï¼‰
                for idx, blue_cnt in enumerate(blue_contours):
                    area = cv2.contourArea(blue_cnt)
                    
                    # é™ä½å•ä¸ªé¢çš„æœ€å°é¢ç§¯è¦æ±‚ï¼Œå› ä¸ºæˆ‘ä»¬è¦æ£€æµ‹å¤šä¸ªé¢
                    min_face_area = max(500, self.blue_min_area * 0.3)  # å•ä¸ªé¢è‡³å°‘æ˜¯æ€»é¢ç§¯çš„30%æˆ–500åƒç´ 
                    if area < min_face_area:
                        continue
                    
                    # è®¡ç®—è¾¹ç•Œæ¡†
                    x, y, w_rect, h_rect = cv2.boundingRect(blue_cnt)
                    if w_rect == 0 or h_rect == 0:
                        continue
                    
                    # è®¡ç®—çŸ©å½¢åº¦ï¼ˆè½®å»“é¢ç§¯ä¸è¾¹ç•Œæ¡†é¢ç§¯çš„æ¯”å€¼ï¼‰
                    bbox_area = w_rect * h_rect
                    if bbox_area == 0:
                        continue
                    rect_ratio = area / bbox_area
                    
                    # è®¡ç®—å®½é«˜æ¯”
                    aspect_ratio = float(w_rect) / h_rect if h_rect > 0 else 0
                    
                    # æ›´å®½æ¾çš„è¿‡æ»¤æ¡ä»¶ï¼ˆå› ä¸ºå¯èƒ½æ˜¯ç›’å­çš„ä¾§é¢ï¼Œå½¢çŠ¶å¯èƒ½ä¸å®Œå…¨è§„åˆ™ï¼‰
                    if rect_ratio < 0.4:  # é™ä½åˆ°0.4
                        continue
                    
                    if aspect_ratio < 0.2 or aspect_ratio > 5.0:  # æ”¾å®½èŒƒå›´
                        continue
                    
                    # è®¡ç®—ä¸­å¿ƒç‚¹
                    M = cv2.moments(blue_cnt)
                    if M['m00'] > 0:
                        cx = int(M['m10'] / M['m00']) + 20
                        cy = int(M['m01'] / M['m00']) + 20
                    else:
                        cx = x + w_rect // 2 + 20
                        cy = y + h_rect // 2 + 20
                    
                    # è·å–æ·±åº¦å€¼å’Œ3Dåæ ‡ï¼ˆé‡‡æ ·å¤šä¸ªç‚¹ä»¥è·å¾—æ›´å‡†ç¡®çš„æ·±åº¦ï¼‰
                    depth_value_mm = 0
                    point_3d = None
                    
                    if self.current_depth is not None and self.tf_handler:
                        try:
                            # åœ¨è½®å»“åŒºåŸŸå†…é‡‡æ ·å¤šä¸ªç‚¹
                            mask = np.zeros((crop_img.shape[0], crop_img.shape[1]), dtype=np.uint8)
                            cv2.drawContours(mask, [blue_cnt], -1, 255, -1)
                            
                            # è½¬æ¢åˆ°åŸå§‹å›¾åƒåæ ‡ï¼ˆæ·±åº¦å›¾åƒæ˜¯åŸå§‹å°ºå¯¸ï¼‰
                            depth_x = x + 20
                            depth_y = y + 20
                            depth_x_end = min(self.current_depth.shape[1], depth_x + w_rect)
                            depth_y_end = min(self.current_depth.shape[0], depth_y + h_rect)
                            depth_x_start = max(0, depth_x)
                            depth_y_start = max(0, depth_y)
                            
                            # åœ¨æ©ç åŒºåŸŸå†…é‡‡æ ·æ·±åº¦å€¼
                            mask_roi = mask[y:y+h_rect, x:x+w_rect]
                            depth_roi = self.current_depth[depth_y_start:depth_y_end, depth_x_start:depth_x_end]
                            
                            # è°ƒæ•´mask ROIçš„å¤§å°ä»¥åŒ¹é…depth ROI
                            if mask_roi.shape != depth_roi.shape:
                                mask_roi_resized = cv2.resize(mask_roi, (depth_roi.shape[1], depth_roi.shape[0]))
                            else:
                                mask_roi_resized = mask_roi
                            
                            valid_depths = depth_roi[(mask_roi_resized > 0) & (depth_roi > 0)]
                            
                            if len(valid_depths) > 0:
                                depth_value_mm = int(np.median(valid_depths))  # ä½¿ç”¨ä¸­ä½æ•°æ›´ç¨³å®š
                                if depth_value_mm > 0 and 30 <= depth_value_mm <= 5000:
                                    point_3d = self.tf_handler.pixel_to_3d(cx, cy, depth_value_mm)
                        except Exception as e:
                            self.get_logger().debug(f'è“è‰²åŒºåŸŸæ·±åº¦è·å–é”™è¯¯: {e}')
                            pass
                    
                    # ä¿å­˜è“è‰²åŒºåŸŸä¿¡æ¯ï¼ˆå¯èƒ½æ˜¯ç›’å­çš„ä¸€ä¸ªé¢ï¼‰
                    region_info = {
                        'contour': blue_cnt,
                        'area': float(area),
                        'bbox': (x, y, w_rect, h_rect),
                        'center_2d': (cx, cy),
                        'depth_mm': float(depth_value_mm),
                        'point_3d': point_3d,
                        'rect_ratio': float(rect_ratio),
                        'aspect_ratio': float(aspect_ratio),
                    }
                    valid_blue_regions.append(region_info)
                
                # æ ¹æ®æ·±åº¦å’Œä½ç½®å°†åŒºåŸŸåˆ†ç»„ä¸ºåŒä¸€ä¸ªç›’å­
                blue_box_groups = []
                depth_tolerance = 50  # æ·±åº¦å®¹å·®ï¼ˆæ¯«ç±³ï¼‰
                position_tolerance = 100  # ä½ç½®å®¹å·®ï¼ˆåƒç´ ï¼‰
                
                for region in valid_blue_regions:
                    if region['point_3d'] is None:
                        # å¦‚æœæ²¡æœ‰æ·±åº¦ä¿¡æ¯ï¼Œæ¯ä¸ªåŒºåŸŸå•ç‹¬æˆç»„
                        blue_box_groups.append([region])
                        continue
                    
                    # å°è¯•æ‰¾åˆ°åŒ¹é…çš„ç»„
                    matched = False
                    for group in blue_box_groups:
                        # æ£€æŸ¥æ˜¯å¦æœ‰æ·±åº¦ä¿¡æ¯
                        group_depths = [r['depth_mm'] for r in group if r['point_3d'] is not None]
                        if len(group_depths) == 0:
                            continue
                        
                        avg_group_depth = np.mean(group_depths)
                        depth_diff = abs(region['depth_mm'] - avg_group_depth)
                        
                        # æ£€æŸ¥ä½ç½®æ˜¯å¦ç›¸è¿‘
                        group_centers = [r['center_2d'] for r in group]
                        avg_center = (np.mean([c[0] for c in group_centers]), 
                                     np.mean([c[1] for c in group_centers]))
                        pos_diff = np.sqrt((region['center_2d'][0] - avg_center[0])**2 + 
                                          (region['center_2d'][1] - avg_center[1])**2)
                        
                        # å¦‚æœæ·±åº¦å’Œä½ç½®éƒ½ç›¸è¿‘ï¼ŒåŠ å…¥è¯¥ç»„
                        if depth_diff < depth_tolerance and pos_diff < position_tolerance:
                            group.append(region)
                            matched = True
                            break
                    
                    if not matched:
                        # åˆ›å»ºæ–°ç»„
                        blue_box_groups.append([region])
                
                # ä¸ºæ¯ä¸ªç»„åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„è“è‰²ç›’å­
                blue_box_idx = 1
                for group in blue_box_groups:
                    if len(group) == 0:
                        continue
                    
                    # è®¡ç®—åˆå¹¶åçš„è¾¹ç•Œæ¡†ï¼ˆåŒ…å«æ‰€æœ‰é¢ï¼‰
                    all_x_min = min([r['bbox'][0] for r in group])
                    all_y_min = min([r['bbox'][1] for r in group])
                    all_x_max = max([r['bbox'][0] + r['bbox'][2] for r in group])
                    all_y_max = max([r['bbox'][1] + r['bbox'][3] for r in group])
                    
                    merged_w = all_x_max - all_x_min
                    merged_h = all_y_max - all_y_min
                    merged_area = sum([r['area'] for r in group])
                    
                    # è®¡ç®—åˆå¹¶åçš„ä¸­å¿ƒç‚¹
                    merged_cx = (all_x_min + all_x_max) // 2 + 20
                    merged_cy = (all_y_min + all_y_max) // 2 + 20
                    
                    # è®¡ç®—å¹³å‡æ·±åº¦å’Œ3Dåæ ‡
                    valid_depths = [r['depth_mm'] for r in group if r['depth_mm'] > 0]
                    avg_depth_mm = int(np.mean(valid_depths)) if len(valid_depths) > 0 else 0
                    
                    # è·å–3Dåæ ‡
                    merged_point_3d = None
                    if avg_depth_mm > 0 and self.current_depth is not None and self.tf_handler:
                        try:
                            merged_point_3d = self.tf_handler.pixel_to_3d(merged_cx, merged_cy, avg_depth_mm)
                        except:
                            pass
                    
                    # è®¡ç®—ç›’å­çš„3Då°ºå¯¸ï¼ˆä½¿ç”¨æ·±åº¦å›¾é‡‡æ ·æ–¹æ³•ï¼ŒåŸºäºbox_dimensionerç®—æ³•ï¼‰
                    box_3d_size = None
                    if self.current_depth is not None and merged_point_3d and self.tf_handler and self.tf_handler.intrinsics:
                        try:
                            # åˆ›å»ºåˆå¹¶åçš„æ©ç ï¼ˆåœ¨åŸå§‹å›¾åƒåæ ‡ç³»ï¼Œç”¨äºé™åˆ¶é‡‡æ ·åŒºåŸŸï¼‰
                            bbox_2d = (
                                all_x_min + 20,  # x_min
                                all_y_min + 20,  # y_min
                                all_x_max + 20,  # x_max
                                all_y_max + 20   # y_max
                            )
                            
                            # åˆ›å»ºåˆå¹¶åçš„æ©ç ï¼ˆåœ¨åŸå§‹å›¾åƒåæ ‡ç³»ï¼‰
                            merged_mask = np.zeros((self.current_depth.shape[0], self.current_depth.shape[1]), dtype=np.uint8)
                            for region in group:
                                contour = region.get('contour')
                                if contour is not None:
                                    # å°†è½®å»“åæ ‡ä»è£å‰ªå›¾åƒåæ ‡ç³»è½¬æ¢åˆ°åŸå§‹å›¾åƒåæ ‡ç³»
                                    adjusted_contour = contour + np.array([20, 20])
                                    cv2.drawContours(merged_mask, [adjusted_contour], -1, 255, -1)
                            
                            # ä½¿ç”¨æ–°çš„3Dæµ‹é‡æ–¹æ³•ï¼ˆåŸºäºbox_dimensionerç®—æ³•ï¼‰
                            dimensions = self.measure_box_dimensions_3d(
                                bbox_2d, 
                                self.current_depth, 
                                mask=merged_mask,
                                sample_step=3  # æ¯3ä¸ªåƒç´ é‡‡æ ·ä¸€æ¬¡ï¼ˆæ›´å¯†é›†ï¼Œæé«˜ç²¾åº¦ï¼‰
                            )
                            
                            if dimensions:
                                box_3d_size = {
                                    'width': dimensions['width'],
                                    'height': dimensions['height'],
                                    'depth': dimensions['depth'],
                                    'num_samples': dimensions.get('num_samples', 0),
                                    'min_point': dimensions.get('min_point'),
                                    'max_point': dimensions.get('max_point')
                                }
                        except Exception as e:
                            self.get_logger().warn(f'ç›’å­3Då°ºå¯¸æµ‹é‡é”™è¯¯: {e}')
                            # å¦‚æœæ–°æ–¹æ³•å¤±è´¥ï¼Œå›é€€åˆ°æ—§æ–¹æ³•
                            if len(valid_depths) > 0:
                                depth_m = avg_depth_mm * 0.001
                                pixel_size = depth_m / self.tf_handler.intrinsics.fx if self.tf_handler.intrinsics.fx > 0 else 0.001
                                box_3d_size = {
                                    'width': merged_w * pixel_size,
                                    'height': merged_h * pixel_size,
                                    'depth': (max(valid_depths) - min(valid_depths)) * 0.001 if len(valid_depths) > 1 else 0.1
                                }
                    
                    # å¦‚æœæ–°æ–¹æ³•æ²¡æœ‰æ‰§è¡Œæˆ–å¤±è´¥ï¼Œä½¿ç”¨æ—§æ–¹æ³•ä½œä¸ºåå¤‡
                    if box_3d_size is None and len(valid_depths) > 0 and merged_point_3d and self.tf_handler and self.tf_handler.intrinsics:
                        depth_m = avg_depth_mm * 0.001
                        pixel_size = depth_m / self.tf_handler.intrinsics.fx if self.tf_handler.intrinsics.fx > 0 else 0.001
                        box_3d_size = {
                            'width': merged_w * pixel_size,
                            'height': merged_h * pixel_size,
                            'depth': (max(valid_depths) - min(valid_depths)) * 0.001 if len(valid_depths) > 1 else 0.1
                        }
                    
                    # ä¿å­˜å®Œæ•´çš„è“è‰²ç›’å­ä¿¡æ¯
                    blue_box_info = {
                        'id': blue_box_idx,
                        'type': 'blue_box',
                        'num_faces': len(group),  # æ£€æµ‹åˆ°çš„é¢æ•°
                        'center': {'x': merged_cx, 'y': merged_cy},
                        'bounding_box': {
                            'x': all_x_min + 20,
                            'y': all_y_min + 20,
                            'width': merged_w,
                            'height': merged_h,
                            'x_min': all_x_min + 20,
                            'y_min': all_y_min + 20,
                            'x_max': all_x_max + 20,
                            'y_max': all_y_max + 20
                        },
                        'area': float(merged_area),
                        'depth_mm': float(avg_depth_mm),
                        'point_3d': merged_point_3d,
                        'size_3d': box_3d_size,
                        'faces': group  # ä¿å­˜æ‰€æœ‰é¢çš„ä¿¡æ¯
                    }
                    blue_box_coordinates.append(blue_box_info)
                    
                    blue_box_idx += 1
                
                # è°ƒè¯•ä¿¡æ¯
                if len(blue_box_coordinates) > 0:
                    self.get_logger().info(f'ğŸ“¦ æ£€æµ‹åˆ° {len(blue_box_coordinates)} ä¸ªè“è‰²ç›’å­')
            
            thresh_yellow_full = None
            if self.detect_yellow_tape:
                # ä½¿ç”¨å¯é…ç½®çš„HSVèŒƒå›´ï¼Œé»˜è®¤èŒƒå›´æ›´ä¸¥æ ¼ä»¥æ£€æµ‹çœŸæ­£çš„é»„è‰²èƒ¶å¸ƒ
                lower_yellow = np.array(self.yellow_hsv_lower, dtype=np.uint8)
                upper_yellow = np.array(self.yellow_hsv_upper, dtype=np.uint8)
                thresh_yellow_hsv = cv2.inRange(hsv, lower_yellow, upper_yellow)
                
                # ä½¿ç”¨æ›´ä¸¥æ ¼çš„å½¢æ€å­¦æ“ä½œï¼Œå»é™¤å°çš„å™ªå£°ç‚¹
                # å…ˆè¿›è¡Œå¼€è¿ç®—å»é™¤å°å™ªå£°ï¼Œç„¶åè¿›è¡Œé—­è¿ç®—è¿æ¥ç›¸è¿‘åŒºåŸŸ
                kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
                thresh_yellow_hsv = cv2.morphologyEx(thresh_yellow_hsv, cv2.MORPH_OPEN, kernel_small, iterations=1)
                thresh_yellow_hsv = cv2.morphologyEx(thresh_yellow_hsv, cv2.MORPH_CLOSE, kernel_small, iterations=1)
                
                # ä½¿ç”¨LABé¢œè‰²ç©ºé—´ä½œä¸ºè¡¥å……ï¼Œä½†ä½¿ç”¨æ›´ä¸¥æ ¼çš„èŒƒå›´
                # åªæ£€æµ‹çœŸæ­£çš„äº®é»„è‰²èƒ¶å¸ƒï¼Œé¿å…æ£€æµ‹åˆ°å¶å­æœ¬èº«çš„é»„è‰²éƒ¨åˆ†
                lab = cv2.cvtColor(crop_img, cv2.COLOR_BGR2LAB)
                # é»„è‰²èƒ¶å¸ƒé€šå¸¸æ˜¯äº®é»„è‰²ï¼šLè¾ƒé«˜ï¼ˆäº®åº¦é«˜ï¼‰ï¼Œaè¾ƒä½ï¼ˆåç»¿ï¼‰ï¼Œbå¾ˆé«˜ï¼ˆåé»„ï¼‰
                # ä½¿ç”¨æ›´ä¸¥æ ¼çš„èŒƒå›´ï¼Œé¿å…è¯¯æ£€å¶å­è¾¹ç¼˜çš„é»„è‰²
                lab_yellow_mask = np.zeros_like(thresh_yellow_hsv, dtype=np.uint8)
                # æ›´ä¸¥æ ¼çš„æ¡ä»¶ï¼šL>110ï¼ˆè¾ƒäº®ï¼‰ï¼Œa<140ï¼ˆåç»¿ï¼‰ï¼Œb>150ï¼ˆå¾ˆé»„ï¼‰
                lab_yellow_mask[(lab[:,:,0] > 110) & (lab[:,:,1] < 140) & (lab[:,:,2] > 150)] = 255
                
                # åˆå¹¶HSVå’ŒLABçš„æ£€æµ‹ç»“æœï¼ˆä¼˜å…ˆä½¿ç”¨ORæ“ä½œï¼Œä½¿æ£€æµ‹æ›´æ•æ„Ÿï¼‰
                # ä¼˜å…ˆä½¿ç”¨ORæ“ä½œï¼Œä½¿æ£€æµ‹æ›´æ•æ„Ÿï¼ˆæ›´å®¹æ˜“æ£€æµ‹åˆ°é»„è‰²èƒ¶å¸ƒï¼‰
                thresh_yellow_full = cv2.bitwise_or(thresh_yellow_hsv, lab_yellow_mask)
                
                # å½¢æ€å­¦å¤„ç†å»é™¤å°å™ªå£°
                kernel_medium = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
                thresh_yellow_full = cv2.morphologyEx(thresh_yellow_full, cv2.MORPH_OPEN, kernel_medium, iterations=1)
                thresh_yellow_full = cv2.morphologyEx(thresh_yellow_full, cv2.MORPH_CLOSE, kernel_medium, iterations=1)
            
            # Morphological processing
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
            thresh_green = cv2.morphologyEx(thresh_green, cv2.MORPH_CLOSE, kernel, iterations=2)
            thresh_green = cv2.morphologyEx(thresh_green, cv2.MORPH_OPEN, kernel, iterations=1)
            
            # Contour detection
            contours, _ = cv2.findContours(thresh_green, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if len(contours) == 0:
                # å³ä½¿æ²¡æœ‰å¶å­ï¼Œå¦‚æœæ£€æµ‹åˆ°è“è‰²ç›’å­ï¼Œä¹Ÿè¦è¿”å›æ•°æ®
                if len(blue_box_coordinates) > 0:
                    result = f"æ£€æµ‹åˆ° {len(blue_box_coordinates)} ä¸ªè“è‰²ç›’å­ï¼ˆæ— å¶å­ï¼‰"
                    leaf_data = {
                        'num_leaves': 0,
                        'num_blue_boxes': len(blue_box_coordinates),
                        'timestamp': datetime.now().isoformat(),
                        'coordinates': [],
                        'blue_boxes': blue_box_coordinates
                    }
                    return result, leaf_data, []
                return "No leaves detected", None, None
            
            # Filtering parameters
            min_area_threshold = min_area if min_area and min_area > 0 else 2000
            max_area = 50000
            min_circularity = 0.2
            max_circularity = 0.9
            
            valid_contours = []
            for cnt in contours:
                area = cv2.contourArea(cnt)
                
                if area < min_area_threshold or area > max_area:
                    continue
                
                perimeter = cv2.arcLength(cnt, True)
                if perimeter == 0:
                    continue
                
                circularity = 4 * np.pi * area / (perimeter * perimeter)
                if circularity < min_circularity or circularity > max_circularity:
                    continue
                
                x, y, w_rect, h_rect = cv2.boundingRect(cnt)
                if w_rect == 0 or h_rect == 0:
                    continue
                
                aspect_ratio = float(w_rect) / h_rect if h_rect > 0 else 0
                if aspect_ratio < 0.4 or aspect_ratio > 2.5:
                    continue
                
                min_dimension = min(w_rect, h_rect)
                if min_dimension < 30:
                    continue
                
                valid_contours.append(cnt)
            
            if len(valid_contours) == 0:
                # å³ä½¿æ²¡æœ‰æœ‰æ•ˆå¶å­ï¼Œå¦‚æœæ£€æµ‹åˆ°è“è‰²ç›’å­ï¼Œä¹Ÿè¦è¿”å›æ•°æ®
                if len(blue_box_coordinates) > 0:
                    result = f"æ£€æµ‹åˆ° {len(blue_box_coordinates)} ä¸ªè“è‰²ç›’å­ï¼ˆæ— æœ‰æ•ˆå¶å­ï¼‰"
                    leaf_data = {
                        'num_leaves': 0,
                        'num_blue_boxes': len(blue_box_coordinates),
                        'timestamp': datetime.now().isoformat(),
                        'coordinates': [],
                        'blue_boxes': blue_box_coordinates
                    }
                    return result, leaf_data, []
                return "No valid leaves detected", None, None
            
            # Extract coordinates (with depth filtering)
            leaf_coordinates = []
            bounding_boxes = []
            leaf_idx = 1
            
            for cnt in valid_contours:
                x, y, w_rect, h_rect = cv2.boundingRect(cnt)
                M = cv2.moments(cnt)
                
                # Calculate center point
                if M['m00'] > 0:
                    cx = int(M['m10'] / M['m00']) + 20
                    cy = int(M['m01'] / M['m00']) + 20
                else:
                    cx = x + w_rect // 2 + 20
                    cy = y + h_rect // 2 + 20
                
                area = cv2.contourArea(cnt)
                perimeter = cv2.arcLength(cnt, True)
                
                # Get depth value and 3D coordinates
                # ä½¿ç”¨å¶å­åŒºåŸŸå†…çš„å¯†é›†é‡‡æ ·ï¼Œé€‰æ‹©æœ€å°æ·±åº¦å€¼ï¼ˆå¶å­åœ¨ç›’å­ä¸Šæ–¹ï¼Œåº”è¯¥æ›´è¿‘ï¼‰
                depth_value_mm = 0
                point_3d = None
                has_valid_depth = False
                
                if self.current_depth is not None and self.tf_handler:
                    try:
                        # æ–¹æ³•1: åœ¨å¶å­è½®å»“åŒºåŸŸå†…å¯†é›†é‡‡æ ·æ·±åº¦å€¼
                        # åˆ›å»ºå¶å­åŒºåŸŸçš„æ©ç 
                        leaf_mask = np.zeros((self.current_depth.shape[0], self.current_depth.shape[1]), dtype=np.uint8)
                        # æ³¨æ„ï¼šcntçš„åæ ‡éœ€è¦è°ƒæ•´ï¼Œå› ä¸ºåŸå§‹å›¾åƒè£å‰ªäº†è¾¹ç¼˜
                        adjusted_cnt = cnt.copy()
                        adjusted_cnt[:, :, 0] = adjusted_cnt[:, :, 0] + 20  # xåæ ‡åç§»
                        adjusted_cnt[:, :, 1] = adjusted_cnt[:, :, 1] + 20  # yåæ ‡åç§»
                        cv2.drawContours(leaf_mask, [adjusted_cnt], -1, 255, -1)
                        
                        # åœ¨æ©ç åŒºåŸŸå†…é‡‡æ ·æ·±åº¦å€¼ï¼ˆæ¯3ä¸ªåƒç´ é‡‡æ ·ä¸€æ¬¡ï¼‰
                        leaf_depths = []
                        for py in range(max(0, y + 20), min(self.current_depth.shape[0], y + h_rect + 20), 3):
                            for px in range(max(0, x + 20), min(self.current_depth.shape[1], x + w_rect + 20), 3):
                                if leaf_mask[py, px] > 0:  # åªåœ¨å¶å­åŒºåŸŸå†…é‡‡æ ·
                                    depth_val = self.current_depth[py, px]
                                    if depth_val > 0 and 100 <= depth_val <= 2000:
                                        leaf_depths.append(depth_val)
                        
                        if len(leaf_depths) > 0:
                            # ä½¿ç”¨æœ€å°æ·±åº¦å€¼ï¼ˆå¶å­åœ¨ç›’å­ä¸Šæ–¹ï¼Œåº”è¯¥æ›´è¿‘ï¼‰
                            # ä½†ä¸ºäº†å»é™¤å™ªå£°ï¼Œä½¿ç”¨å‰20%æœ€å°å€¼çš„å¹³å‡å€¼
                            sorted_depths = sorted(leaf_depths)
                            num_samples = max(1, int(len(sorted_depths) * 0.2))  # å‰20%çš„æœ€å°å€¼
                            depth_value_mm = int(np.mean(sorted_depths[:num_samples]))
                            
                            if depth_value_mm > 0 and 100 <= depth_value_mm <= 2000:
                                has_valid_depth = True
                                point_3d = self.tf_handler.pixel_to_3d(cx, cy, depth_value_mm)
                        else:
                            # å›é€€æ–¹æ³•ï¼šä½¿ç”¨ä¸­å¿ƒç‚¹é™„è¿‘çš„åŒºåŸŸ
                            if cx < self.current_depth.shape[1] and cy < self.current_depth.shape[0]:
                                # ä½¿ç”¨5x5åŒºåŸŸï¼Œå–æœ‰æ•ˆæ·±åº¦çš„æœ€å°å€¼
                                y_start = max(0, cy - 2)
                                y_end = min(self.current_depth.shape[0], cy + 3)
                                x_start = max(0, cx - 2)
                                x_end = min(self.current_depth.shape[1], cx + 3)
                                depth_region = self.current_depth[y_start:y_end, x_start:x_end]
                                valid_depths = depth_region[(depth_region > 0) & (depth_region >= 100) & (depth_region <= 2000)]
                                
                                if len(valid_depths) > 0:
                                    depth_value_mm = int(np.min(valid_depths))  # ä½¿ç”¨æœ€å°å€¼ï¼ˆæœ€æµ…çš„æ·±åº¦ï¼‰
                                    has_valid_depth = True
                                    point_3d = self.tf_handler.pixel_to_3d(cx, cy, depth_value_mm)
                    except Exception as e:
                        self.get_logger().debug(f'Leaf depth sampling error: {e}')
                        pass
                
                if not has_valid_depth:
                    continue
                
                has_yellow_tape = False
                yellow_ratio = 0.0
                if self.detect_yellow_tape and thresh_yellow_full is not None:
                    # åˆ›å»ºå¶å­åŒºåŸŸçš„æ©ç ï¼ˆä½¿ç”¨å®Œæ•´çš„è½®å»“ï¼Œè€Œä¸æ˜¯è¾¹ç•Œæ¡†ï¼‰
                    # è¿™æ ·å¯ä»¥æ›´å‡†ç¡®åœ°æ£€æµ‹å¶å­å†…éƒ¨çš„é»„è‰²åŒºåŸŸ
                    leaf_mask = np.zeros_like(thresh_green, dtype=np.uint8)
                    cv2.drawContours(leaf_mask, [cnt], -1, 255, -1)
                    
                    # ç›´æ¥åœ¨å®Œæ•´æ©ç ä¸Šè®¡ç®—ï¼Œè€Œä¸æ˜¯ä½¿ç”¨è¾¹ç•Œæ¡†åŒºåŸŸ
                    # è¿™æ ·å¯ä»¥é¿å…è¾¹ç•Œæ¡†å¯èƒ½åŒ…å«éå¶å­åŒºåŸŸçš„é—®é¢˜
                    leaf_pixels = np.sum(leaf_mask > 0)
                    yellow_pixels = np.sum((leaf_mask > 0) & (thresh_yellow_full > 0))
                    
                    if leaf_pixels > 0:
                        yellow_ratio = yellow_pixels / leaf_pixels
                        
                        # é¢å¤–çš„éªŒè¯ï¼šæ£€æŸ¥é»„è‰²åŒºåŸŸçš„è¿é€šæ€§å’Œå¤§å°
                        # çœŸæ­£çš„é»„è‰²èƒ¶å¸ƒåº”è¯¥æ˜¯è¿ç»­çš„ã€æœ‰ä¸€å®šå¤§å°çš„åŒºåŸŸ
                        yellow_in_leaf = (leaf_mask > 0) & (thresh_yellow_full > 0)
                        yellow_contours, _ = cv2.findContours(
                            yellow_in_leaf.astype(np.uint8), 
                            cv2.RETR_EXTERNAL, 
                            cv2.CHAIN_APPROX_SIMPLE
                        )
                        
                        # è®¡ç®—æœ€å¤§é»„è‰²è¿é€šåŒºåŸŸçš„é¢ç§¯
                        max_yellow_area = 0
                        if len(yellow_contours) > 0:
                            max_yellow_area = max(cv2.contourArea(c) for c in yellow_contours)
                        
                        # é™ä½æœ€å°åŒºåŸŸè¦æ±‚ï¼šè‡³å°‘50åƒç´ æˆ–å¶å­é¢ç§¯çš„0.5%ï¼ˆæ›´å®¹æ˜“æ£€æµ‹ï¼‰
                        min_yellow_area_threshold = max(50, leaf_pixels * 0.005)
                        
                        # ä½¿ç”¨ORæ¡ä»¶ï¼šæ»¡è¶³æ¯”ä¾‹é˜ˆå€¼æˆ–æœ€å°åŒºåŸŸè¦æ±‚ä¹‹ä¸€å³å¯ï¼ˆæ›´å®¹æ˜“æ£€æµ‹ï¼‰
                        if (yellow_ratio >= self.yellow_ratio_threshold or 
                            max_yellow_area >= min_yellow_area_threshold):
                            has_yellow_tape = True
                            
                            # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•æ£€æµ‹åˆ°çš„é»„è‰²æ ‡ç­¾ä¿¡æ¯
                            self.get_logger().info(
                                f'ğŸ¯ Leaf {leaf_idx}: æ£€æµ‹åˆ°é»„è‰²æ ‡ç­¾ - '
                                f'yellow_ratio={yellow_ratio:.4f} '
                                f'(é˜ˆå€¼={self.yellow_ratio_threshold:.4f}), '
                                f'é»„è‰²åƒç´ ={yellow_pixels}/{leaf_pixels}, '
                                f'æœ€å¤§è¿é€šåŒºåŸŸ={max_yellow_area:.0f}åƒç´ '
                            )
                        else:
                            # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•æœªé€šè¿‡éªŒè¯çš„æƒ…å†µ
                            if yellow_ratio > 0.01:  # åªè®°å½•æœ‰æ˜æ˜¾é»„è‰²ä½†æœªè¾¾é˜ˆå€¼çš„æƒ…å†µ
                                reason = []
                                if yellow_ratio < self.yellow_ratio_threshold:
                                    reason.append(f'æ¯”ä¾‹ä¸è¶³({yellow_ratio:.4f}<{self.yellow_ratio_threshold:.4f})')
                                if max_yellow_area < min_yellow_area_threshold:
                                    reason.append(f'åŒºåŸŸå¤ªå°({max_yellow_area:.0f}<{min_yellow_area_threshold:.0f})')
                                self.get_logger().debug(
                                    f'âš ï¸ Leaf {leaf_idx}: æ£€æµ‹åˆ°é»„è‰²ä½†æœªé€šè¿‡éªŒè¯ - '
                                    f'yellow_ratio={yellow_ratio:.4f}, '
                                    f'æœ€å¤§è¿é€šåŒºåŸŸ={max_yellow_area:.0f}åƒç´ , '
                                    f'åŸå› : {", ".join(reason)}'
                                )
                    else:
                        # è°ƒè¯•ï¼šå¦‚æœå¶å­åŒºåŸŸä¸ºç©ºï¼Œè®°å½•è­¦å‘Š
                        self.get_logger().warn(
                            f'âš ï¸ Leaf {leaf_idx}: å¶å­åŒºåŸŸæ©ç ä¸ºç©ºï¼Œæ— æ³•æ£€æµ‹é»„è‰²æ ‡ç­¾ '
                            f'(bbox: x={x}, y={y}, w={w_rect}, h={h_rect}, '
                            f'mask_shape={leaf_mask.shape})'
                        )
                
                # Save leaf info
                leaf_info = {
                    'id': leaf_idx,
                    'center': {'x': cx, 'y': cy},
                    'bounding_box': {
                        'x': x + 20,
                        'y': y + 20,
                        'width': w_rect,
                        'height': h_rect,
                        'x_min': x + 20,
                        'y_min': y + 20,
                        'x_max': x + 20 + w_rect,
                        'y_max': y + 20 + h_rect
                    },
                    'area': float(area),
                    'perimeter': float(perimeter),
                    'depth_mm': float(depth_value_mm),
                    'point_3d': point_3d,
                    'has_yellow_tape': has_yellow_tape,
                    'yellow_ratio': float(yellow_ratio),
                    'health_status': 'unhealthy' if has_yellow_tape else 'healthy'
                }
                leaf_coordinates.append(leaf_info)
                
                bounding_boxes.append({
                    'id': leaf_idx,
                    'center_x': cx,
                    'center_y': cy,
                    'width': w_rect,
                    'height': h_rect,
                    'x': x + 20,
                    'y': y + 20
                })
                
                leaf_idx += 1
            
            
            num_detected_leaves = len(leaf_coordinates)
            
            if num_detected_leaves == 0:
                # å³ä½¿æ·±åº¦è¿‡æ»¤åæ²¡æœ‰å¶å­ï¼Œå¦‚æœæ£€æµ‹åˆ°è“è‰²ç›’å­ï¼Œä¹Ÿè¦è¿”å›æ•°æ®
                if len(blue_box_coordinates) > 0:
                    result = f"æ£€æµ‹åˆ° {len(blue_box_coordinates)} ä¸ªè“è‰²ç›’å­ï¼ˆå¶å­æ·±åº¦è¿‡æ»¤åï¼‰"
                    leaf_data = {
                        'num_leaves': 0,
                        'num_blue_boxes': len(blue_box_coordinates),
                        'timestamp': datetime.now().isoformat(),
                        'coordinates': [],
                        'blue_boxes': blue_box_coordinates
                    }
                    return result, leaf_data, []
                return "No valid leaves detected (after depth filtering)", None, None
            
            # ç»Ÿè®¡é»„è‰²æ ‡ç­¾æ£€æµ‹ç»“æœ
            yellow_tape_count = sum(1 for leaf in leaf_coordinates if leaf.get('has_yellow_tape', False))
            if yellow_tape_count > 0:
                self.get_logger().info(
                    f'ğŸ“Š æ£€æµ‹æ€»ç»“: å…±{num_detected_leaves}ç‰‡å¶å­, '
                    f'å…¶ä¸­{yellow_tape_count}ç‰‡æ£€æµ‹åˆ°é»„è‰²æ ‡ç­¾'
                )
                # åˆ—å‡ºæ‰€æœ‰æœ‰é»„è‰²æ ‡ç­¾çš„å¶å­
                for leaf in leaf_coordinates:
                    if leaf.get('has_yellow_tape', False):
                        self.get_logger().info(
                            f'  âœ“ Leaf {leaf["id"]}: yellow_ratio={leaf.get("yellow_ratio", 0):.4f}'
                        )
            
            result = f"Detected {num_detected_leaves} leaves"
            if len(blue_box_coordinates) > 0:
                result += f", {len(blue_box_coordinates)} blue boxes"
            
            leaf_data = {
                'num_leaves': num_detected_leaves,
                'num_blue_boxes': len(blue_box_coordinates),
                'timestamp': datetime.now().isoformat(),
                'coordinates': leaf_coordinates,
                'blue_boxes': blue_box_coordinates
            }
            
            return result, leaf_data, bounding_boxes
            
        except Exception as e:
            self.get_logger().error(f'âœ— PlantCV detection error: {str(e)}')
            return f"Detection error: {str(e)}", None, None
    
    def draw_annotations(self, display_frame, leaf_coordinates, blue_box_coordinates=None):
        """Draw annotations on image"""
        if display_frame is None:
            return None
        
        # Always return a copy of the frame (with or without annotations)
        annotated = display_frame.copy()
        
        if blue_box_coordinates is None:
            blue_box_coordinates = []
        
        if not leaf_coordinates and not blue_box_coordinates:
            # No leaves or boxes detected, just return original frame
            return annotated
        
        # Draw annotations for detected leaves
        try:
            colors = [
                (255, 0, 0),      # Blue
                (0, 255, 0),      # Green
                (0, 0, 255),      # Red
                (255, 255, 0),    # Cyan
                (255, 0, 255),    # Magenta
                (0, 255, 255),    # Yellow
            ]
            
            for leaf in leaf_coordinates:
                obj_id = leaf['id']
                color = colors[(obj_id - 1) % len(colors)]
                
                bbox = leaf['bounding_box']
                x = bbox['x_min']
                y = bbox['y_min']
                x_max = bbox['x_max']
                y_max = bbox['y_max']
                
                # Draw bounding box
                cv2.rectangle(annotated, (x, y), (x_max, y_max), color, 2)
                
                # Draw label - å¢å¤§å­—ä½“å’ŒèƒŒæ™¯
                label = f'Leaf {obj_id}'
                if leaf.get('has_yellow_tape', False):
                    label += ' [Tape]'
                font_scale_leaf = 0.8  # å¢å¤§å­—ä½“
                thickness_leaf = 2
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale_leaf, thickness_leaf)[0]
                label_y = max(y - 10, label_size[1] + 10)
                
                # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯ï¼ˆæ›´æ¸…æ™°ï¼‰
                overlay = annotated.copy()
                cv2.rectangle(overlay, (x - 2, label_y - label_size[1] - 8),
                            (x + label_size[0] + 8, label_y + 8), color, -1)
                cv2.addWeighted(overlay, 0.7, annotated, 0.3, 0, annotated)
                cv2.rectangle(annotated, (x - 2, label_y - label_size[1] - 8),
                            (x + label_size[0] + 8, label_y + 8), color, 2)
                cv2.putText(annotated, label, (x + 3, label_y - 3),
                           cv2.FONT_HERSHEY_SIMPLEX, font_scale_leaf, (255, 255, 255), thickness_leaf)
                
                # Draw center point
                cx = leaf['center']['x']
                cy = leaf['center']['y']
                cv2.circle(annotated, (cx, cy), 5, color, -1)
                cv2.circle(annotated, (cx, cy), 15, color, 2)
                
                # Draw 3D coordinates if available - å¢å¤§å­—ä½“
                point_3d = leaf.get('point_3d')
                if point_3d:
                    coord_text = f"Z:{point_3d[2]:.2f}m"
                    font_scale_coord = 0.6
                    thickness_coord = 2
                    coord_text_size = cv2.getTextSize(coord_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale_coord, thickness_coord)[0]
                    
                    # ç»˜åˆ¶èƒŒæ™¯
                    text_bg_y = y_max - 5
                    overlay = annotated.copy()
                    cv2.rectangle(overlay, (x + 3, text_bg_y - coord_text_size[1] - 5),
                                (x + coord_text_size[0] + 8, text_bg_y + 5), (0, 0, 0), -1)
                    cv2.addWeighted(overlay, 0.6, annotated, 0.4, 0, annotated)
                    
                    cv2.putText(annotated, coord_text,
                               (x + 5, text_bg_y),
                               cv2.FONT_HERSHEY_SIMPLEX, font_scale_coord, (255, 255, 255), thickness_coord)
            
            # ç»˜åˆ¶è“è‰²ç›’å­ï¼ˆæ˜¾ç¤ºæ‰€æœ‰æ£€æµ‹åˆ°çš„é¢ï¼‰
            blue_box_color = (255, 0, 0)  # è“è‰²ç”¨äºè“è‰²ç›’å­ (BGRæ ¼å¼)
            face_color = (200, 100, 100)  # æµ…è“è‰²ç”¨äºå•ä¸ªé¢
            for blue_box in blue_box_coordinates:
                obj_id = blue_box['id']
                bbox = blue_box['bounding_box']
                x = bbox['x_min']
                y = bbox['y_min']
                x_max = bbox['x_max']
                y_max = bbox['y_max']
                
                # ç»˜åˆ¶åˆå¹¶åçš„å®Œæ•´è¾¹ç•Œæ¡†ï¼ˆç²—çº¿ï¼‰
                cv2.rectangle(annotated, (x, y), (x_max, y_max), blue_box_color, 3)
                
                # ç»˜åˆ¶æ¯ä¸ªæ£€æµ‹åˆ°çš„é¢ï¼ˆç»†çº¿ï¼‰
                num_faces = blue_box.get('num_faces', 1)
                faces = blue_box.get('faces', [])
                if len(faces) > 0:
                    # ç»˜åˆ¶æ¯ä¸ªé¢çš„è½®å»“
                    for face_idx, face in enumerate(faces):
                        contour = face.get('contour')
                        if contour is not None:
                            # è°ƒæ•´è½®å»“åæ ‡ï¼ˆåŠ ä¸Šè£å‰ªåç§»ï¼‰
                            adjusted_contour = contour + np.array([20, 20])
                            cv2.drawContours(annotated, [adjusted_contour], -1, face_color, 1)
                
                # ç»˜åˆ¶æ ‡ç­¾ï¼ˆæ˜¾ç¤ºé¢æ•°ï¼‰- å¢å¤§å­—ä½“å’ŒèƒŒæ™¯
                label = f'Blue Box {obj_id}'
                if num_faces > 1:
                    label += f' ({num_faces} faces)'
                font_scale_label = 0.8  # å¢å¤§å­—ä½“
                thickness_label = 2
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale_label, thickness_label)[0]
                label_y = max(y - 10, label_size[1] + 10)
                
                # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯ï¼ˆæ›´æ¸…æ™°ï¼‰
                overlay = annotated.copy()
                cv2.rectangle(overlay, (x - 2, label_y - label_size[1] - 8),
                            (x + label_size[0] + 8, label_y + 8), blue_box_color, -1)
                cv2.addWeighted(overlay, 0.7, annotated, 0.3, 0, annotated)
                cv2.rectangle(annotated, (x - 2, label_y - label_size[1] - 8),
                            (x + label_size[0] + 8, label_y + 8), blue_box_color, 2)
                cv2.putText(annotated, label, (x + 3, label_y - 3),
                           cv2.FONT_HERSHEY_SIMPLEX, font_scale_label, (255, 255, 255), thickness_label)
                
                # ç»˜åˆ¶ä¸­å¿ƒç‚¹
                cx = blue_box['center']['x']
                cy = blue_box['center']['y']
                cv2.circle(annotated, (cx, cy), 5, blue_box_color, -1)
                cv2.circle(annotated, (cx, cy), 15, blue_box_color, 2)
                
                # å¦‚æœå¯ç”¨ï¼Œç»˜åˆ¶3Dåæ ‡å’Œå°ºå¯¸ - å¢å¤§å­—ä½“ï¼Œæ”¹å–„å¸ƒå±€
                point_3d = blue_box.get('point_3d')
                size_3d = blue_box.get('size_3d')
                if point_3d:
                    font_scale_info = 0.7  # å¢å¤§ä¿¡æ¯å­—ä½“
                    thickness_info = 2
                    line_height = 25  # è¡Œé—´è·
                    
                    # åªæ˜¾ç¤ºå°ºå¯¸ä¿¡æ¯ï¼ˆé•¿å®½é«˜ï¼‰
                    if size_3d:
                        size_text = f"L:{size_3d['width']*100:.1f}cm  H:{size_3d['height']*100:.1f}cm  W:{size_3d['depth']*100:.1f}cm"
                        size_text_size = cv2.getTextSize(size_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale_info, thickness_info)[0]
                        
                        # ç»˜åˆ¶èƒŒæ™¯
                        text_bg_y = y_max - 5
                        overlay = annotated.copy()
                        cv2.rectangle(overlay, (x + 3, text_bg_y - size_text_size[1] - 5),
                                    (x + size_text_size[0] + 8, text_bg_y + 5), (0, 0, 0), -1)
                        cv2.addWeighted(overlay, 0.6, annotated, 0.4, 0, annotated)
                        
                        cv2.putText(annotated, size_text,
                                   (x + 5, text_bg_y),
                                   cv2.FONT_HERSHEY_SIMPLEX, font_scale_info, (255, 255, 255), thickness_info)
            
            # Display total count - å¢å¤§å­—ä½“å’ŒèƒŒæ™¯
            total_text = f"Leaves: {len(leaf_coordinates)}"
            if len(blue_box_coordinates) > 0:
                total_text += f" | Blue Boxes: {len(blue_box_coordinates)}"
            font_scale_total = 1.0
            thickness_total = 3
            total_text_size = cv2.getTextSize(total_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale_total, thickness_total)[0]
            
            # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯
            overlay = annotated.copy()
            cv2.rectangle(overlay, (8, 8),
                        (total_text_size[0] + 12, total_text_size[1] + 20), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.6, annotated, 0.4, 0, annotated)
            
            cv2.putText(annotated, total_text, (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale_total, (0, 255, 0), thickness_total)
            
            return annotated
            
        except Exception as e:
            self.get_logger().error(f'âœ— Annotation drawing error: {str(e)}')
            return display_frame.copy()

